{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "web_scrapper_paises.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPVFWg5NYnRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from openpyxl import Workbook\n",
        "from openpyxl import Workbook, load_workbook\n",
        "from openpyxl.drawing.image import Image\n",
        "from openpyxl.utils.dataframe import dataframe_to_rows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w19aQgplH18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gyd8cxHliDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# obtains list of countries\n",
        "\n",
        "def get_country_list():\n",
        "  page_paises_rec = requests.get(\"https://www.numbeo.com/cost-of-living/\")\n",
        "      \n",
        "  soup = BeautifulSoup(page_paises_rec.content, 'html.parser')\n",
        "\n",
        "  paises_rec_var = [x.text for x in soup.find_all('select', {'id': 'country'})]\n",
        "\n",
        "  # edits the data to facilitate its use\n",
        "\n",
        "    # split string based on '\\n'\n",
        "  lista_paises_temp = [i.split('\\n') for i in paises_rec_var]\n",
        "    # Deletes null values\n",
        "  del lista_paises_temp[0][0:2]\n",
        "  del lista_paises_temp[0][-1]\n",
        "  \n",
        "  lista_paises = lista_paises_temp[0]\n",
        "  \n",
        "  return lista_paises\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyqYxs60lFVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creates excel file\n",
        "def create_output_file():\n",
        "  new_file_path = '/content/drive/My Drive/Colab Notebooks/webScrapper proj/Paises_WS.xlsx'\n",
        "  wb_paises = Workbook(new_file_path)\n",
        "  wb_paises.save(new_file_path)\n",
        "\n",
        "#create_output_file()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xd6BAwtIkmD1",
        "colab": {}
      },
      "source": [
        "\n",
        "def extract_info():\n",
        "\n",
        "  get_country_list()\n",
        "  \n",
        "  for i in range(len(lista_paises)):\n",
        "    \n",
        "    # target url + iteration variable that pulls countries from the country list\n",
        "    page_paises = requests.get(\"https://www.numbeo.com/cost-of-living/country_result.jsp?country=%s&displayCurrency=EUR\" % lista_paises[i])\n",
        "      \n",
        "    page_paises\n",
        "\n",
        "    soup = BeautifulSoup(page_paises.content, 'html.parser')\n",
        "\n",
        "    # list tha will receive the extracted values\n",
        "    lista_val = []\n",
        "\n",
        "    #print(lista_paises[i])\n",
        "\n",
        "    # difenes the information fields to target; prices of the various items\n",
        "    z = soup.find_all('td', class_=\"priceValue\")\n",
        "    list(z)\n",
        "    \n",
        "    # appents country name\n",
        "    lista_val.append(lista_paises[i])\n",
        "\n",
        "    # the loop iterates thru various defined fields in the website and appends values\n",
        "    for x in range(len(z)):\n",
        "      \n",
        "      # appends values extrated to extration list\n",
        "      lista_val.append(z[x].get_text())\n",
        "      \n",
        "    ## excel append section ##\n",
        "\n",
        "    #path to the excel file\n",
        "    excel_file = '/content/drive/My Drive/Colab Notebooks/webScrapper proj/Paises_WS.xlsx'\n",
        "\n",
        "    #load excel file\n",
        "    wb_p2 = load_workbook(excel_file)\n",
        "\n",
        "    #declares the active sheet were to append\n",
        "    f1 = wb_p2.active\n",
        "\n",
        "    #appends values to declared sheet\n",
        "    f1.append(lista_val)\n",
        "\n",
        "    #saves changes made to the excel file\n",
        "    wb_p2.save(filename=excel_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS8ihM9wRAot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# functon calls\n",
        "\n",
        "# get country list\n",
        "#get_country_list()\n",
        "\n",
        "# extracts info\n",
        "extract_info()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}